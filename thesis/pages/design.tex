\chapter{Design}
In diesem Kapitel geht es darum die Vor- und Nachteile der unterschiedlichen
Bibliotheken anhand eines praktischen Beispieles zu zeigen. Dabei wird
\enquote{gelly-streaming} als Referenz-Implementierung benutzt. Zunächst wird
allgemein der Ablauf des Beispiel beschrieben. Dann wird die Architektur
der Referenz beschrieben. Anschließend werden die Entwürfe für die anderen
Bibliotheken beschrieben und was die Besonderheiten in Bezug auf die Referenz
sind. Abschließend werden die Probleme der Bibliotheken benannt und mögliche
Lösungsmöglichkeiten benannt.

\section{Analyse des Beispieles}
In dem Beispiel geht es darum zu überprüfen, ob ein Graph bipartite ist oder
nicht. Dies bedeutet, ob ein Graph zweifarbig färbbar ist. Um dies für einen
existierenden Graphen zu lösen, gibt es verschiedene Algorithmen. Die allgemeine
Vorgehensweise ist dabei ähnlich.

Am Begin sind alle Knoten ungefärbt. Dann werden zwei Farben gewählt.
Anschließend wird ein Startknoten gewählt und dieser in einer der Farben markiert.
Dann werden die unmarkierten Nachbarknoten in der anderen Farbe markiert. Danach
werden deren unmarkierte Nachbarknoten wieder in der ersten Farbe markiert, usw.
bis alle Knoten makiert sind. Ein Graph ist dann bipartite, wenn alle Knoten so
markiert sind, dass keine benachbarten Knoten die selbe Farbe haben. Diese
Vorgehensweise kann jeder selbst für kleine Graphen selbst durchführen. Je nachdem
welche Informationen über den zu überprüfenden Graphen existieren, kann der Ablauf
auch verkürzt werden. Wenn der Graph nämlich einen Kreis von ungerader Länge
enthällt ist, kann der Graph nie bipartite sein unabhängig vom gewählten
Startknoten. Die Abbildung \ref{fig:bipartite-six-nodes} zeigt einen bipartiten
Graphen mit einen Kreis der Länge sechs. Während dessen die Abbildung \ref{fig:bipartite-five-nodes}
einen nicht bipartiten Graphen zeigt. Denn der Kreis hat eine ungerade Länge und
lässt sich damit nie mit zwei Farben färben egal welcher Startknoten gewählt
wurde. 

\begin{figure}
\centering
\includegraphics[scale=0.5]{../material/images/bipartite-graph-six-nodes.jpg}
\caption{bipartiter Graph mit Kreis der Länge sechs \cite{GeeksforGeeks2018}}
\label{fig:bipartite-six-nodes}
\end{figure}

\begin{figure}
\centering
\includegraphics[scale=0.5]{../material/images/bipartite-graph-five-nodes.jpg}
\caption{nicht bipartiter Graph mit Kreis der Länge fünf \cite{GeeksforGeeks2018}}
\label{fig:bipartite-five-nodes}
\end{figure}


Wie läuft das Beispiel nun konkret ab. Zunächst werden die Daten eingelesen. Dies
erfolgt zur Vereinfachung über eine Datei. Dies kann jedoch jederzeit auf eine
alternative Eingabe umgestellt werden zum Beispiel um die Daten von einem
Messaging-System wie Apache Kafka einlesen zu können. Dabei ist zu beachten,
dass alle Bibliotheken, verschiedene Eingabeformate haben. Anschließend werden
die Daten an eine beliebige Ausgabe gesendet. Dies ist in unserem Fall einfach
die Konsole.

\subsection{Architektur der Referenz-Implementierung}
Die Anwendung besteht aus drei Teilen, welche wie eine Fileterkette aufgebaut
sind Eingabe, Verarbeitung und Starten. Alle drei Teile definieren einen Apache
Flink Job und in jede Anwendung sollte maximal nur einen Job umsetzen. Zunächst
muss die Streaming-Engine initialisiert werden. Dabei ist es von Vorteil, zu
wissen ob die spätere Anwendung nur lokal oder remote betrieben werden soll.
Lokal bedeutet in diesem Zusammmenhang, dass die Anwendung einen Apache Flink
Cluster in der selben JVM startet. Dies lässt sich bereits bei der Entwicklung
fest einzuprogrammieren oder dynamisch von Apache Flink bestimmen lassen.

\foreigntextquote{english}[\cite{Foundation2018}]{
The LocalStreamEnvironment is a StreamExecutionEnvironment that runs the program
locally, multi-threaded, in the JVM where the environment is instantiated. It
spawns an embedded Flink cluster in the background and executes the program on
that cluster.}

Danach können die eigentlichen Daten eingelesen werden. Dazu kann ein von Apache
vordefinierter Connector zum Beispiel für Dateien benutzt werden oder eine
Bibliothek. In diesem Beispiel wird der File-Connector benutzt, welcher im Kern
von Apache Flink enthalten ist. Die Umwandlung von Text zu Kanten muss für jede
Anwendung neu definiert und programmiert werden. Im Beispiel liegen die Daten
wie schon erwähnt in einer Datei vor. Dabei besteht jede Zeile aus genau einer
Kante. Jede Kante besteht dabei aus zwei Identifikationsnummern für die Kanten,
welche durch ein Tabulator getrennt sind. Alle Kanten sind in Apache Flink
gerichtete Kanten. Eine ungerichtete Kante kann nur erzeugt werden, wenn es eine
zweite Kante gibt, bei der die Anfangs- und End-Identifikationsnummern vertauscht
sind.

\foreigntextquote{english}[\cite{Foundation2018}]{
In Gelly an Edge is always directed from the source vertex to the target vertex.
A Graph may be undirected if for every Edge it contains a matching Edge from the
target vertex to the source vertex.}

Anschließend erfolgt die richtige Datenverarbeitung bei der das Filter-Pattern
zur Anwendung kommt, wie es auch bei anderen Anwendungen, wie Map-Reduce zum
Einsatz kommt. Dabei wird auch die Ausgabe mit definiert. Im Beispiel wird der
Graph dann überprüft, ob dieser bipartite ist oder nicht. Dabei werden die Daten
in einem temporären Stream mit Fenster zwischengespeichert. Die Überprüfung wird
in eine Aggretationsfunktion eingebettet um die Zwischenergebnisse zu speichern.
Als letztes wird der Job dann gestartet. Dabei wird in der lokalen Umgebung dann
der Cluster gestartet.

\subsection{Entwurf von \enquote{graphstream-project}}
Die Umsetzung des Beispiel ist ähnlich wie eine normale Java-Anwendung zu
programmieren. Zunächst wird die Eingabe definiert. In \enquote{graphstream-project}
sind werden Eingabe-Komponenten als \enquote{Sources} bezeichnet. Hier in diesem
Beispiel werden die Graphendaten wieder von einer Datei bereitgestellt. Die
Bibliothek stellt ein Protokoll zur Datenübertragung bereit. Dadurch ist eine
einfache Kommunikation auch mit anderen Systemen möglich. Das Protokoll hat dabei
Ähnlichkeiten zum \enquote{Portable Bitmap File} Format. Beide Protokolle haben
am Anfang einen Kopf für die Meta-Informationen bevor die eigentlichen Daten
folgen. Im Unterschied zu \enquote{gelly-streaming} lassen sich die Kanten
genau spezifizieren.

\foreigntextquote{english}[\cite{Team2018}]{
ae Allows to add an edge. This command must be followed by the unique identifier
of the edge, and then the identifiers of two other nodes. As for nodes, you can
specify a parameter list. It is possible to create directed edges by adding a
“>” (greater-than) or “<” (smaller-than) character between the nodes identifiers.
This indicates the direction of the edge. When no “<” or “>” is present, the
edge is not directed.}

Die Quelle wird dann mit einer Graph-Instanz verbunden. Denn es ist möglich
den Graphen durch den Aufruf von Methoden zu ändern.

Die Implementierung von Algorithmen erfolgt bei \enquote{graphstream-project}
über das Interface Algorithm. Dieses stellt zwei Methoden bereit init und compute.
Die Methode init bekommt einen Graphen übergeben und initialisiert den
Algorithmus. Die compute Methode führt die eigentliche Berechnung aus.
Die Resultate des Algorithmus werden über selbst programmiert Getter
bereitgestellt.

Die Ausgabe erfolgt über einen Aufruf der Konsole.

\subsection{Entwurf von \enquote{Gephi}}
Die Umsetzung des Beispieles von Gephi ist anders, als die anderen. Dort
existieren mehrere Möglichkeiten diese Problem zu lösen.

Die erste Möglichkeit besteht darin ein neues Statistik-Plug-In zu entwickeln
und das bestehende Streaming-Plug-In nur für die Datenübertragung zu verwenden.
Dies hätte den Vorteil, dass sehr viel von \enquote{Gephi} übernommen werden
kann und nicht in die Kommunikation eingegriffen werden muss. Die Dateineingabe
muss bei diesem Szenarion über einen geeingeten HTTP-Service erfolgen, der
die Kommunikation mit den exterenen Systemem wie zum Beispiel Apache Kafka
übernimmt und die eingehenden Daten in das entsprechenden Format konvertiert.
Die Berechnung würde dann im Programm erfolgen ebenso die Ausgabe.

Die andere Möglichkeit ergibt sich durch die direkte Benutzung des
Streaming-Plug-Ins. Das Streaming-Plugin von \enquote{Gephi} basiert wie schon
beschrieben auf HTTP. Dabei kann \enquote{Gephi} beide Seiten der
Client-Server-Verbindung representieren je nach Anwendungsfall. Die
Datenübertragung erfolgt dabei standartmäßig im JSON-Format. Somit ergeben sich
zwei mögliche Szenarien.

Das erste Szenario benutzt die Möglichkeit \enquote{Gephi} als Server zu
betreiben. Dabei wird eine \enquote{Gephi}-Instanz gestartet mit einem
Arbeitsbereich als Master. Die Dateneingabe muss dabei von einem externen
Tool bzw. Dienst übernommen werden. Wie schon bei der ersten Möglichkeit. Daraus
ergibt sich auch die ähnlichkeit zur ersten Möglichkeit. Die Datenverarbeitung
erfolgt jedoch über einen anderen Weg. Der erste Weg ist die Verarbeitung im
Tool zu übernehmen und diese dort auch anzuzeigen. Das Problem bei dieser Variante
ist, dass das Ergebnis nicht von der \gls{API} übertragen werden kann, diese
ist nur für Manipulationen des Graphen geeignet. Der zweite Weg stellt kann
dabei eine Lösung sein in dem die \gls{API} um eine geeignete Methode erweitert
wird. Problem bei dieser Variante ist, wie die Darstellung erfolgen kann.

Das zweite Szenario benutzt die Client-Möglichkeit von \enquote{Gephi}. Bei
dieser Variante werden die Komponenten von \enquote{Gephi} benutzt, deshalb
ist eine Plug-In Implementierung notwendig. Zunächst einmal wird die aktuelle
Graph-Instanz benötigt. Diese Instanz stellt der GraphController bereit, dessen
aktuelle Referenz zuerst abgefragt werden muss. Als nächstes wird eine Referenz
des StreamingControllers benötigt, welche ebenfalls abgefragt werden muss.
Anschließend kann der Endpoint konfiguriert werden. Der StreamingController
bekommt danach den Endpoint und den Graphen übermittelt und liefert, die
Verbindung zurück, welchen abschließend gestartet werden kann. Die Aktualisierung
der Oberfläche erfolgt dabei automatisch. Optional existiert auch die Möglichkeit
Ereignis-Handler zu registrieren um beim schließen der Verbindung spezielle
Schritte zu tätigen. Wenn dies wie in unserem Fall nicht ausreicht und zusätzlich
Schritte erfolgen sollen als nur den Graphen zu aktualisieren, dann wird die
Hilfe eines GraphEventHandler benötigt. Das Listing \ref{code:GephiGraphHandler}
zeigt den prototypischen Einsatz eines solchen Handlers. Dieser Handler kann dann
alle gewünschten Operationen ausführen je nach Anwendungsfall. Diese Variante ist
jedoch Abstraktionsebene tiefer als, wenn der StreamingController direkt
verwendet wird.

\begin{listing}
\inputminted[breaklines=true]{java}{../material/code/GephiGraphHandler.java}
\caption{prototypischer Einsatz für einen GraphHandler}
\label{code:GephiGraphHandler}
\end{listing}

\section{Bewertung und Alternativen}
Beim Vergleich der Bibliotheken in der Analysephase fällt auf, dass alle
Bibliotheken noch im experimentellen Stadium sind. Deshalb sind sie nicht nicht
für den produktiven Einsatz geeignet, jedoch haben alle schon gute Ansätze bzw.
ihre Vor- und Nachteile.

Zunächst benutzen die Bibliotheken unterschiedliche Informationen und Darstellungen
für die Graph-Daten. Die Referenz \enquote{gelly-streaming} stellt dabei die
wenigsten Informationen bereit. Dort wird lediglich die IDs und ein Wert
gespeichert jedoch keine zusätzlichen Meta-Informationen zum Beispiel ob die
Kante hinzugefügt wurde, wie dies bei den anderen Bibliotheken der Fall ist.
Es bringt einem Entwickler auch nichts diese Daten mit zu übertragen, da die
Klasse Edge, welche eine Kante representiert, von Apache Flink nur zwei IDs und
einen Wert speichern kann. Somit haben hier die beiden anderen Bibliotheken klar
einen Vorteil was die Informationsmenge angeht. Ob diese Informationen letzlich
immer benötigt werden hängt natürlich stark von den Anforderungen der jeweiligen
Anwendung ab.

Wie schon oben erwähnt, könnte ein Entwickler die zusätzlichen Daten mit
übertragen und dann bei \enquote{gelly-streaming} die Konvertierung übernehmen.
Allerdings wird dann das nicht vorhandene Protokoll von \enquote{gelly-streaming}
zum Problem. Der Entwickler hat zwar die Freiheit beliebige Daten zu übertragen,
allerdings muss bei jedem neuen Projekt genau definiert werden, wie die zu
übertragenden Daten auszusehen haben. Dies kann gerade bei vielen Projekten zum
Problem werden. Da im Standartfall einfach eine Zeichenkette zur Verfügung steht.
Es existieren allerdings schon Ansätze diese Problemetik zu lösen. Apache Flink
stellt Basisklassen für verschiedene Dateiformate bereit zum Beispiel
BinaryInputFormat, CsvInputFormat,~\dots . Damit kann ein Entwickler konkrete
Protokolle definieren bzw. gibt bei einer CSV-Datei nur die Trennzeichen an.

Die Referenz \enquote{gelly-streaming} hat Vorteile, bei der Streaming-Umgebung
und der Verteilung. Dies kommt natürlich daher, dass Apache Flink in diesen
Punkten schon über einen guten Entwicklungsstand verfügt. Darum ist
\enquote{gelly-streaming} auch die einzige Bibliothek, welche sich verteilt
betreiben lässt. Beim Vergleich der gesammten Streaming-Umgebung ist
\enquote{gelly-streaming} klar am vorschrittlichsten. Es gibt ein eigenes
Konzept für Streams, welches je nach Anforderung konfiguriert werden kann. In
unserem Beispiel soll ein einfacher Test nach Ablauf eines Zeitfensters
durchgeführt werden. Bei \enquote{gelly-streaming} wird zur Lösung dieses
Problems eine Window-Stream über den Test konfiguriert. Bei \enquote{graphstream-project}
wird ein andere Event-System-Ansatz gewählt. Dort hat der Entwickler die
Möglichkeit zu entscheiden ob alle Events auf einmal eingelesen werden sollen
oder nicht. Die Möglichkeit konkrete Zeitfenster zu definieren gibt es bei
\enquote{graphstream-project} nicht. Es kann lediglich abgefragt werden, ob noch
neue Events vorhanden sind. Auf die eigentlichen Events kann nicht zugegriffen
werden, sondern lediglich auf den vollständigen Graphen. Das Listing
\ref{code:GraphStreamInput} zeigt den Ablauf zum Einlesen von Events. Bei \enquote{Gephi}
kann über einen speziellen GraphEventHandler auf die Events zugegriffen werden.
Allerdings ist auch dort kein Zeitfenster vorgesehen.

\begin{listing}
\inputminted[breaklines=true]{java}{../material/code/GraphStreamInput.java}
\caption{prototypischer Ablauf zum Einlesen von Daten bei \enquote{graphstream-project}}
\label{code:GraphStreamInput}
\end{listing}

Beim Vergleich der Unterstützung von Algorithmen haben alle Bibliotheken noch
große Problem, obwohl bei \enquote{gelly-streaming} eigentlich mehr zu erwarten
währe auf Grund der Verbindung zu Apache Flink und der Bibliothek \enquote{Gelly}.
Denn dort werden schon einige Graph-Algorithmen definiert, welche jedoch nicht in
\enquote{gelly-streaming} verwendet werden. Des Weiteren stellt \enquote{Gelly}
ein Interface GraphAlgorithm bereit, womit ein Entwickler eigene Graph-Algorithmen
entwickeln kann. Diese Möglichkeit gibt es bei \enquote{gelly-streaming} nicht.
Dies hat dort auch zur Folge, dass alle selbst definierten Algorithmen eine
Erweiterung vom SummaryAggregation sein müssen. Dies macht eine Entwicklung
neuer Algorithmen schwerere. Denn die meisten Algorithmen für die
Graph-Verabeitung lassen sich als Map-Reduce-Probleme beschreiben. Beim Interface
GraphAlgorithm ist dies so vorgesehen, denn dieses Interface hat nur eine
run-Methode in der die konkreten Methodenaufrufe gekapselt werden. Bei
\enquote{graphstream-project} existiert ebenfals ein Interface Algorithm für die
Implementierung von Graph-Algorithmen. Dies ist als sogenanntes Marker-Interface
konzipiert. Das bedeutet, dass alle Klassen, welche dieses Interface
implementieren einen Graph-Algorithmus darstellen. Jedoch wird dieses Interface
nicht in anderen Klassen für zum Beispiel Polymorphismus,~\dots eingesetzt. Dies
lässt sich auch ganz klar an der Interface-Struktur ablesen. Das Interface selbst
besteht aus zwei Methoden einer init-Methode für die Initialisierung des
Algorithmuses und einer compute-Methode für die Berechnung. Die Rückgabewerte
müssen über selbst definierte Getter an den Aufrufer zurückgegeben werden. Dies
ist aber im Interface nicht vorgesehen. Um diese Einschränkung aufzuheben muss
das Interface angepasst werden entweder um eine Getter Methode oder die
compute-Methode wird um einen Rückgabewerte erweitert. Allerdings ergibt sich
dabei die Frage, was passiert, wenn mehr als ein Rückgabewerte benötigt wird.







Bei der Ausführung des Beispiels fällt auf, dass für jede neue Kante ein
Ergebnis produziert wird. Dies sollte eigentlich nicht passieren, da ja ein
Fenster aktiv sein sollte und somit nur pro Fenster ein Ergebnis geliefert
werden sollte. Es kann natürlich daran liegen, dass die Daten aus einer Datei
eingelesen werden und nicht von einem Socket oder ähnliches.
%% In der Umsetzung beschreiben

